{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "from math import sqrt, fabs, exp\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.linear_model import enet_path\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path =r'/Users/Bruce/desktop/stat242_2015/project'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_data = pd.read_csv(\"train.csv\",sep=\",\")\n",
    "scale_data = sales_data.shape\n",
    "\n",
    "\n",
    "#### random sample to generate training data and test data\n",
    "\n",
    "random.seed(1223)\n",
    "\n",
    "sample_index = random.sample(range(0, scale_data[0]-1), int (0.8*(scale_data[0]-1)))\n",
    "\n",
    "### generate training data\n",
    "\n",
    "sale_train = sales_data.ix[sample_index]\n",
    "\n",
    "labels = sale_train[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sale_train.drop('target',axis = 1 , inplace = True)\n",
    "\n",
    "sale_train_x = sale_train\n",
    "\n",
    "sale_train_x.drop(\"id\",axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows = sale_train_x.index\n",
    "rows = list(rows)\n",
    "row_count = len(rows)\n",
    "\n",
    "train_index = random.sample(list(rows), int (0.8*row_count))\n",
    "test_index = sale_train_x.index.delete(train_index)\n",
    "\n",
    "### training sets of X variables\n",
    "Xtrain = sale_train_x.ix[train_index]\n",
    "### training sets of labels\n",
    "\n",
    "Ytrain = labels.ix[train_index]\n",
    "Ytrain = pd.Categorical(Ytrain)\n",
    "Ytrain = np.unique(Ytrain, return_inverse=True)[1]\n",
    "\n",
    "\n",
    "### test sets of X variables\n",
    "Xtest = sale_train_x.ix[test_index]\n",
    "Ytest = labels.ix[test_index]\n",
    "Ytest = pd.Categorical(Ytest)\n",
    "Ytest = np.unique(Ytest, return_inverse=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nTreeList = range(1,101,1)\n",
    "missCLassError_RF = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for iTrees in nTreeList:\n",
    "    depth = 18\n",
    "    otto_classify = RandomForestClassifier(n_estimators=iTrees,\n",
    "        max_depth=depth, max_features=\"sqrt\",\n",
    "        oob_score=False, random_state=1223,n_jobs = 4)\n",
    "\n",
    "\n",
    "    otto_classify.fit(Xtrain,Ytrain)\n",
    "\n",
    "    #Accumulate auc on test set\n",
    "    prediction = otto_classify.predict(Xtest)\n",
    "\n",
    "    correct = accuracy_score(Ytest, prediction)\n",
    "\n",
    "    missCLassError_RF.append(1.0 - correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15504049148282606"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(missCLassError_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min(missCLassError_RF)\n",
    "min_bool = (missCLassError_RF ==min(missCLassError_RF))\n",
    "min_bool\n",
    "best_ntree = nTreeList[min_bool.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ntree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## extreme tree method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nTreeList = range(1,101,1)\n",
    "\n",
    "missCLassError_extreme = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for iTrees in nTreeList:\n",
    "    depth = 18\n",
    "    otto_extreme = ExtraTreesClassifier(n_estimators=iTrees,\n",
    "        max_depth=depth, max_features=\"sqrt\",\n",
    "        oob_score=False, random_state=1223,n_jobs = 4)\n",
    "\n",
    "\n",
    "    otto_extreme.fit(Xtrain,Ytrain)\n",
    "\n",
    "    #Accumulate auc on test set\n",
    "    prediction = otto_extreme.predict(Xtest)\n",
    "\n",
    "    correct = accuracy_score(Ytest, prediction)\n",
    "\n",
    "    missCLassError_extreme.append(1.0 - correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25601787210276461"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min (missCLassError_extreme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "min_bool_extre = (missCLassError_extreme ==min(missCLassError_extreme))\n",
    "min_bool_extre\n",
    "best_ntree_extre = nTreeList[min_bool_extre.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ntree_extre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "otto_GBM = GradientBoostingClassifier(n_estimators=100,\n",
    "                    max_depth=10,learning_rate=0.05,\n",
    "                    max_features=\"sqrt\",subsample=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.05, loss='deviance',\n",
       "              max_depth=10, max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2, n_estimators=100,\n",
       "              random_state=None, subsample=0.5, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otto_GBM.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " # compute auc on test set as function of ensemble size\n",
    "missClassError_GB = []\n",
    "missClassBest = 1.0\n",
    "predictions = otto_GBM.staged_decision_function(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for p in predictions:\n",
    "    missClass = 0\n",
    "    for i in range(len(p)):\n",
    "        listP = p[i].tolist()\n",
    "        if listP.index(max(listP)) != Ytest[i]:\n",
    "            missClass += 1\n",
    "    missClass = float(missClass)/len(p)\n",
    "    missClassError_GB.append(missClass)\n",
    "    #capture best predictions\n",
    "    if missClass < missClassBest:\n",
    "        missClassBest = missClass\n",
    "pBest = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idxBest = missClassError_GB.index(min(missClassError_GB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Missclassification Error\n",
      "0.1357162803686121\n",
      "Number of Trees for Best Missclassification Error\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Missclassification Error\" )\n",
    "print(missClassBest)\n",
    "print(\"Number of Trees for Best Missclassification Error\")\n",
    "print(idxBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot.plot(nTreeList,missCLassError_RF)\n",
    "plot.plot(nTreeList,missCLassError_extreme)\n",
    "plot.plot(range(1, 100 + 1), missClassError_GB, label='Test Set Error')\n",
    "plot.xlabel('Number of Trees in Ensemble')\n",
    "plot.ylabel('Classification Error')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix\n",
      "[[ 420   21    2    0    1   22    8   37   33]\n",
      " [   1 4263  235    9    0    3   10    4    1]\n",
      " [   0  618 1655    5    0    2   15    4    2]\n",
      " [   0  181   64  533    1   16    4    0    0]\n",
      " [   0    7    0    0  815    0    0    0    0]\n",
      " [   4   33    2    2    0 4115   18   32   22]\n",
      " [   5   70   29    3    2   20  694   19    5]\n",
      " [   8   17    6    0    1   23    9 2281   17]\n",
      " [  11   27    4    0    0   18    8   22 1386]]\n"
     ]
    }
   ],
   "source": [
    "pBestList = pBest.tolist()\n",
    "bestPrediction = [r.index(max(r)) for r in pBestList]\n",
    "confusionMat = confusion_matrix(Ytest, bestPrediction)\n",
    "print('')\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusionMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### FIT THE MODEL USING ALL THE TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## combine all the training data\n",
    "X_all = sale_train_x\n",
    "labels_all = sale_train[\"target\"]\n",
    "labels_all = pd.Categorical(labels_all)\n",
    "Y_all = np.unique(labels_all, return_inverse=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## test data after using all training data to fit the model\n",
    "sale_test = sales_data.drop(sales_data.index[sample_index])\n",
    "label_test = sale_test[\"target\"]\n",
    "## change to factor\n",
    "label_test = pd.Categorical(label_test)\n",
    "label_test = np.unique(label_test,return_inverse = True)[1]\n",
    "sale_test.drop('target',axis = 1 , inplace = True)\n",
    "sale_test_x  =  sale_test\n",
    "sale_test_x.drop(\"id\",axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.05, loss='deviance',\n",
       "              max_depth=10, max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2, n_estimators=100,\n",
       "              random_state=None, subsample=0.5, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##fit the gradient boosting model using all the training data\n",
    "otto_GBM.fit(X_all, Y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_test = otto_GBM.staged_decision_function(sale_test_x)\n",
    "missClassError_new=[]\n",
    "for p in predictions_test:\n",
    "    missClass = 0\n",
    "    for i in range(len(p)):\n",
    "        listP = p[i].tolist()\n",
    "        if listP.index(max(listP)) != label_test[i]:\n",
    "            missClass += 1\n",
    "    missClass = float(missClass)/len(p)\n",
    "    missClassError_new.append(missClass)\n",
    "    #capture best predictions\n",
    "    if missClass < missClassBest:\n",
    "        missClassBest = missClass\n",
    "pBest = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxBest_test = missClassError_new.index(min(missClassError_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Missclassification Error\n",
      "0.09734710974588104\n",
      "Number of Trees for Best Missclassification Error\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Missclassification Error\" )\n",
    "print(missClassBest)\n",
    "print(\"Number of Trees for Best Missclassification Error\")\n",
    "print(idxBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## fit best model of random forest and predict using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "otto_classify_best = RandomForestClassifier(n_estimators=25,\n",
    "        max_depth=18, max_features=\"sqrt\",\n",
    "        oob_score=False, random_state=1223,n_jobs = 4)\n",
    "otto_classify_best.fit(X_all, Y_all)\n",
    "    #Accumulate auc on test set\n",
    "prediction_best = otto_classify_best.predict(sale_test_x)\n",
    "correct = accuracy_score(label_test, prediction_best)\n",
    "missCLassError_best = 1.0 - correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## fit best model of extra trees and predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "otto_extreme = ExtraTreesClassifier(n_estimators=37,\n",
    "        max_depth=18, max_features=\"sqrt\",\n",
    "        oob_score=False, random_state=1223,n_jobs = 4)\n",
    "otto_extreme.fit(X_all,Y_all)\n",
    " #Accumulate auc on test set\n",
    "prediction = otto_extreme.predict(sale_test_x)\n",
    "correct = accuracy_score(label_test, prediction)\n",
    "missCLassError_best_ET = 1.0 - correct\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
