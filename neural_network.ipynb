{
 "metadata": {
  "name": "242_neural_network"
 }, 
 "name": "242_neural_network", 
 "nbformat": 2, 
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": "from nolearn import lasagne\nimport numpy as np", 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stderr", 
       "text": "Using gpu device 0: Tesla K40c"
      }
     ], 
     "prompt_number": 1
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "from pandas.io.parsers import read_csv", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 2
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "from sklearn import cross_validation", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 3
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "import cPickle as pickle", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 4
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "from random import seed, sample", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 5
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "sales_data = read_csv(\"xsfeng/train.csv\")\nseed(1223)", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 6
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "scale_data = sales_data.shape\nsample_index = sample(range(0, scale_data[0]-1), int (0.8*(scale_data[0]-1)))", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 7
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "testing = sales_data.drop(sales_data.index[sample_index])", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 8
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "training = sales_data.ix[sample_index]", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 9
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "from sklearn.preprocessing import StandardScaler, LabelEncoder", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 10
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "raw_data = training.values.copy()\ntraining_features = raw_data[:, -1]\ntraining_data = raw_data[:, 1:-1]", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 11
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "raw_data = testing.values.copy()\ntesting_features = raw_data[:, -1]\ntesting_data = raw_data[:, 1:-1]", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 12
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "scaler = StandardScaler()\ntraining_data_scaled = scaler.fit_transform(training_data).astype(np.float32)\ntesting_data_scaled = scaler.fit_transform(testing_data).astype(np.float32)", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 13
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "encoder = LabelEncoder()\ny = encoder.fit_transform(training_features).astype(np.int32)\nyy = encoder.fit_transform(testing_features).astype(np.int32)", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 14
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "from lasagne.layers import DenseLayer\nfrom lasagne.layers import InputLayer\nfrom lasagne.layers import DropoutLayer, FlattenLayer\nfrom lasagne.layers import NonlinearityLayer\nfrom lasagne.layers import Conv1DLayer, FeaturePoolLayer, ReshapeLayer, MaxPool1DLayer\nfrom lasagne.layers import Conv2DLayer, MaxPool2DLayer\nfrom lasagne.nonlinearities import softmax, linear, sigmoid, tanh\nfrom lasagne.updates import nesterov_momentum, adagrad, rmsprop, sgd\nfrom nolearn.lasagne import NeuralNet", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 15
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "net0 = NeuralNet(layers=[\n                         ('input', InputLayer),\n                         ('hidden1', DenseLayer),\n                         ('dropout1', DropoutLayer),\n                         ('hidden2', DenseLayer),\n                         ('dropout2', DropoutLayer),\n                         ('hidden3', DenseLayer),\n                         #('hidden4', DenseLayer),\n                         ('output', DenseLayer)\n                         ],\n                 input_shape=(None, 93),\n                 \n                 hidden1_num_units = 256,\n                 dropout1_p = 0.2,\n                 hidden2_num_units = 512,\n                 dropout2_p = 0.4,\n                 hidden3_num_units = 256,\n                 #hidden4_num_units = 256,\n                 output_num_units=9, \n                 output_nonlinearity=softmax,\n                 \n                 update=nesterov_momentum,\n                 update_learning_rate=0.01,\n                 update_momentum=0.9,\n                 \n                 eval_size=0.2,\n                 verbose=1,\n                 max_epochs=40\n                 )", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 17
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": "res = net0.fit(training_data_scaled, y)", 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stderr", 
       "text": "/home/yuduo/.local/lib/python2.7/site-packages/Lasagne-0.1.dev-py2.7.egg/lasagne/init.py:86: UserWarning: The uniform initializer no longer uses Glorot et al.'s approach to determine the bounds, but defaults to the range (-0.01, 0.01) instead. Please use the new GlorotUniform initializer to get the old behavior. GlorotUniform is now the default for all layers.\n  warnings.warn(\"The uniform initializer no longer uses Glorot et al.'s \"\n/home/yuduo/.local/lib/python2.7/site-packages/Lasagne-0.1.dev-py2.7.egg/lasagne/layers/helper.py:69: UserWarning: get_all_layers() has been changed to return layers in topological order. The former implementation is still available as get_all_layers_old(), but will be removed before the first release of Lasagne. To ignore this warning, use `warnings.filterwarnings('ignore', '.*topo.*')`.\n  warnings.warn(\"get_all_layers() has been changed to return layers in \"\n/home/yuduo/.local/lib/python2.7/site-packages/nolearn/lasagne.py:376: UserWarning: layer.get_output_shape() is deprecated and will be removed for the first release of Lasagne. Please use layer.output_shape instead.\n  output_shape = layer.get_output_shape()\n/home/yuduo/.local/lib/python2.7/site-packages/nolearn/lasagne.py:283: UserWarning: layer.get_output(...) is deprecated and will be removed for the first release of Lasagne. Please use lasagne.layers.get_output(layer, ...) instead.\n  output_layer.get_output(X_batch), y_batch)\n/home/yuduo/.local/lib/python2.7/site-packages/theano/sandbox/rng_mrg.py:768: UserWarning: MRG_RandomStreams Can't determine #streams from size (Shape.0), guessing 60*256\n  nstreams = self.n_streams(size)\n/home/yuduo/.local/lib/python2.7/site-packages/nolearn/lasagne.py:285: UserWarning: layer.get_output(...) is deprecated and will be removed for the first release of Lasagne. Please use lasagne.layers.get_output(layer, ...) instead.\n  output_layer.get_output(X_batch, deterministic=True), y_batch)"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "  DenseLayer        \t(None, 9)           \tproduces       9 outputs\n  DenseLayer        \t(None, 256)         \tproduces     256 outputs\n  DropoutLayer      \t(None, 512)         \tproduces     512 outputs\n  DenseLayer        \t(None, 512)         \tproduces     512 outputs\n  DropoutLayer      \t(None, 256)         \tproduces     256 outputs\n  DenseLayer        \t(None, 256)         \tproduces     256 outputs\n  InputLayer        \t(None, 93)          \tproduces      93 outputs\n\n Epoch  |  Train loss  |  Valid loss  |  Train / Val  |  Valid acc  |  Dur\n--------|--------------|--------------|---------------|-------------|-------"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n     1  |  \u001b[94m  0.926709\u001b[0m  |  \u001b[32m  0.661161\u001b[0m  |     1.401639  |     74.60%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n     2  |  \u001b[94m  0.678813\u001b[0m  |  \u001b[32m  0.611143\u001b[0m  |     1.110726  |     76.07%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n     3  |  \u001b[94m  0.635745\u001b[0m  |  \u001b[32m  0.588901\u001b[0m  |     1.079545  |     76.90%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n     4  |  \u001b[94m  0.613061\u001b[0m  |  \u001b[32m  0.574954\u001b[0m  |     1.066279  |     77.36%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n     5  |  \u001b[94m  0.592535\u001b[0m  |  \u001b[32m  0.564618\u001b[0m  |     1.049443  |     77.68%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n     6  |  \u001b[94m  0.576900\u001b[0m  |  \u001b[32m  0.553846\u001b[0m  |     1.041625  |     78.06%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n     7  |  \u001b[94m  0.569373\u001b[0m  |  \u001b[32m  0.553191\u001b[0m  |     1.029252  |     78.19%  |  1.2s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n     8  |  \u001b[94m  0.554539\u001b[0m  |  \u001b[32m  0.549737\u001b[0m  |     1.008735  |     77.98%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n     9  |  \u001b[94m  0.548070\u001b[0m  |  \u001b[32m  0.541522\u001b[0m  |     1.012093  |     78.45%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    10  |  \u001b[94m  0.537844\u001b[0m  |  \u001b[32m  0.537484\u001b[0m  |     1.000669  |     78.47%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    11  |  \u001b[94m  0.530094\u001b[0m  |  \u001b[32m  0.534176\u001b[0m  |     0.992359  |     78.81%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    12  |  \u001b[94m  0.523348\u001b[0m  |  \u001b[32m  0.530643\u001b[0m  |     0.986253  |     78.91%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    13  |  \u001b[94m  0.519988\u001b[0m  |  \u001b[32m  0.527058\u001b[0m  |     0.986587  |     78.78%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    14  |  \u001b[94m  0.513196\u001b[0m  |  \u001b[32m  0.526604\u001b[0m  |     0.974538  |     79.18%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    15  |  \u001b[94m  0.506297\u001b[0m  |  \u001b[32m  0.523261\u001b[0m  |     0.967581  |     78.97%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    16  |  \u001b[94m  0.498857\u001b[0m  |  \u001b[32m  0.520181\u001b[0m  |     0.959007  |     79.21%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    17  |  \u001b[94m  0.492455\u001b[0m  |    0.520393  |     0.946312  |     79.21%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    18  |  \u001b[94m  0.492383\u001b[0m  |  \u001b[32m  0.516250\u001b[0m  |     0.953768  |     79.44%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    19  |  \u001b[94m  0.484693\u001b[0m  |    0.519878  |     0.932321  |     79.35%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    20  |  \u001b[94m  0.479497\u001b[0m  |    0.517631  |     0.926330  |     79.40%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    21  |  \u001b[94m  0.473908\u001b[0m  |  \u001b[32m  0.514716\u001b[0m  |     0.920718  |     79.59%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    22  |  \u001b[94m  0.472905\u001b[0m  |  \u001b[32m  0.514041\u001b[0m  |     0.919976  |     79.62%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    23  |  \u001b[94m  0.466496\u001b[0m  |    0.515159  |     0.905538  |     79.77%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    24  |  \u001b[94m  0.464215\u001b[0m  |    0.514095  |     0.902976  |     79.62%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    25  |  \u001b[94m  0.462083\u001b[0m  |    0.514890  |     0.897441  |     79.43%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    26  |  \u001b[94m  0.457919\u001b[0m  |    0.514179  |     0.890584  |     79.70%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    27  |  \u001b[94m  0.452461\u001b[0m  |  \u001b[32m  0.511925\u001b[0m  |     0.883842  |     79.72%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    28  |  \u001b[94m  0.449416\u001b[0m  |  \u001b[32m  0.511271\u001b[0m  |     0.879017  |     79.70%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    29  |  \u001b[94m  0.448338\u001b[0m  |    0.514868  |     0.870783  |     79.49%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    30  |  \u001b[94m  0.441288\u001b[0m  |  \u001b[32m  0.510892\u001b[0m  |     0.863760  |     79.81%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    31  |  \u001b[94m  0.438447\u001b[0m  |  \u001b[32m  0.509545\u001b[0m  |     0.860467  |     80.11%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    32  |  \u001b[94m  0.435058\u001b[0m  |    0.511065  |     0.851278  |     79.82%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    33  |  \u001b[94m  0.429827\u001b[0m  |  \u001b[32m  0.509412\u001b[0m  |     0.843771  |     80.01%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    34  |  \u001b[94m  0.428756\u001b[0m  |    0.511553  |     0.838145  |     79.91%  |  1.2s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    35  |  \u001b[94m  0.425742\u001b[0m  |    0.510660  |     0.833709  |     79.95%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    36  |  \u001b[94m  0.423715\u001b[0m  |    0.513011  |     0.825937  |     80.03%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    37  |  \u001b[94m  0.422619\u001b[0m  |    0.510199  |     0.828340  |     80.16%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    38  |  \u001b[94m  0.419175\u001b[0m  |    0.512544  |     0.817831  |     80.00%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    39  |  \u001b[94m  0.409576\u001b[0m  |    0.512283  |     0.799510  |     80.26%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": "\n    40  |    0.412280  |    0.512201  |     0.804918  |     80.21%  |  1.1s"
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": ""
      }, 
      {
       "output_type": "stream", 
       "stream": "stderr", 
       "text": "/home/yuduo/.local/lib/python2.7/site-packages/nolearn/lasagne.py:286: UserWarning: layer.get_output(...) is deprecated and will be removed for the first release of Lasagne. Please use lasagne.layers.get_output(layer, ...) instead.\n  predict_proba = output_layer.get_output(X_batch, deterministic=True)"
      }
     ], 
     "prompt_number": 18
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "rr = res.predict(testing_data_scaled)", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 19
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": "from sklearn.metrics import confusion_matrix\nm = confusion_matrix(rr, yy)", 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 20
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": "np.matrix.trace(m).astype(float32) / shape(testing_data)[0] ", 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 21, 
       "text": "0.80391047911448654"
      }
     ], 
     "prompt_number": 21
    }
   ]
  }
 ]
}